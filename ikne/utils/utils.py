import functools
import torch
import torch.nn.functional as F
import open3d as o3d
import numpy as np
from torch_scatter import scatter_mean


def cuda_cast(func):

    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        new_args = []
        for x in args:
            if hasattr(x, 'cuda'):
                x = x.cuda()
            new_args.append(x)
        new_kwargs = {}
        for k, v in kwargs.items():
            if hasattr(v, 'cuda'):
                v = v.cuda()
            elif isinstance(v, list) and hasattr(v[0], 'cuda'):
                v = [x.cuda() for x in v]
            new_kwargs[k] = v
        return func(*new_args, **new_kwargs)

    return wrapper


class AverageMeter(object):
    """Computes and stores the average and current value."""

    def __init__(self, apply_dist_reduce=False):
        self.apply_dist_reduce = apply_dist_reduce
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def get_val(self):
        return self.val

    def get_avg(self):
        return self.avg

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


def gather_similar_points(sim, tau=0.8):
    '''
    Args.
        sim: Similarity matrix between same tensor;     [N x N]
    
    Return.
        indices list: list which contains gathered point indices
    '''    
    threshold = sim.max() * tau
    topsim_per_row = torch.sum(sim > threshold, dim=1)

    sort_idx = torch.argsort(topsim_per_row, descending=True)

    visited = torch.zeros(len(topsim_per_row)).bool().cuda()
    indices_list = []
    for i in sort_idx:
        if visited[i]:
            continue
        over_thres_idx = (sim[i] >= threshold)
        over_thres_idx = (over_thres_idx & ~visited).nonzero()[:, 0]
        over_thres_idx = torch.hstack([over_thres_idx, i])
        visited[i] = True
        visited[over_thres_idx] = True
        # indices_list.append(over_thres_idx.cpu().numpy())
        if len(over_thres_idx) > 1:
            indices_list.append(over_thres_idx)

    return indices_list


def visualize_pcd(coords, instance_idx):
    num_inst = len(instance_idx)
    inst_color = np.random.uniform(0, 1, [int(num_inst)+1, 3])

    pcd_list = []
    all_pcd = o3d.geometry.PointCloud()
    all_pcd.points = o3d.utility.Vector3dVector(coords.cpu().detach().numpy())
    all_pcd.paint_uniform_color([0.5, 0.5, 0.5])
    pcd_list.append(all_pcd)

    for i in range(num_inst):
        inst_idx = instance_idx[i]
        if len(inst_idx) <= 1:
            continue
        inst_pcd = o3d.geometry.PointCloud()
        inst_pcd.points = o3d.utility.Vector3dVector(coords[inst_idx].cpu().detach().numpy())
        inst_pcd.paint_uniform_color(inst_color[i])
        pcd_list.append(inst_pcd)

    o3d.visualization.draw(pcd_list, show_skybox=False, show_ui=True, bg_color=(0.0, 0.0, 0.0, 0.0))


def get_query_from_point_idx(lowest_feats, lowest_coords, indices_list, num_query=400):
    """
    Args.
        lowest_feats: Poiny/voxel features that have lowest resolution;     list:[batch] [num points, 160(feat_dim)]
        lowest_coords: Point/voxel coordinates that have lowest resolution;     list:[batch] [num points, 3(x, y, z)]
        indices_list: Point/voxel indices which have high similarity between other points;  list: [batch] [num pseudo inst] (index)
        num_query: number of query that is indicated in configuration;  default = 400

    Returns.
        query: Pseudo query generated by scatter-mean between high sim indices;     [B, num inst + zero pad(num query), 160]
    """
    query = []
    q_pos = []
    for b in range(len(lowest_feats)):
        query_per_batch = []
        q_pos_per_batch = []
        for idx in indices_list[b]:
            pseudo_query = torch.mean(lowest_feats[b][idx], dim=0)    # [1, 160]
            query_pos = torch.mean(lowest_coords[b][idx], dim=0)

            query_per_batch.append(pseudo_query)
            q_pos_per_batch.append(query_pos)
            
        query_per_batch = torch.stack(query_per_batch, dim=0)
        query_per_batch = F.pad(query_per_batch, (0, 0, 0, num_query-query_per_batch.shape[0]), 'constant', 0)
        query.append(query_per_batch)
    
    query = torch.stack(query, dim=0)   # [B, num query, 160]
    return query.cuda()
